{
  "paper": {
    "id": "orr5uPZY28",
    "forum": "orr5uPZY28",
    "title": "DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure",
    "authors": "Yunfan Xiong, Ruoyu Zhang, Yanzeng Li, Tianhao Wu, Lei Zou",
    "keywords": "inference methods, efficient inference, speculative decoding",
    "abstract": "While speculative decoding has recently appeared as a promising direction for accelerating the inference of large language models (LLMs), the speedup and scalability are strongly bounded by the token acceptance rate.\nPrevalent methods usually organize predicted tokens as independent chains or fixed token trees, which fails to generalize to diverse query distributions. \nIn this paper, we propose \\textsc{DySpec}, a faster speculative decoding algorithm with a novel dynamic token tree structure. \nWe begin by bridging the draft distribution and acceptance rate from \nintuitive and empirical clues, and successfully show that the two variables are strongly correlated. Based on this, we employ a greedy strategy to dynamically expand the token tree at run time. Theoretically, we show that our method can achieve optimal results under mild assumptions. Empirically, \\textsc{DySpec} yields a higher acceptance rate and speedup than fixed trees. \\textsc{DySpec} can drastically improve the throughput and reduce the latency of token generation across various data distribution and model sizes, which significantly outperforms strong competitors, including Specinfer and Sequoia. Under low temperature setting, \\textsc{DySpec} can improve the throughput up to 9.10x and reduce the latency up to 9.4x on Llama2-70B. Under high temperature setting, \\textsc{DySpec} can also improve the throughput up to 6.21x, despite the increasing difficulty of speculating more than one token per step for draft model.",
    "pdf_link": "https://openreview.net/pdf/4fc6d00e6765877101d3c2e16f096e4bc3631ba1.pdf",
    "submission_date": "2024-09-28 11:45:07.412000"
  },
  "reviews": [
    {
      "note_id": "BtO2O0dCy8",
      "replyto": "orr5uPZY28",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-11-04 01:39:47.291000",
      "modified": "2024-11-12 16:14:32.500000",
      "signatures": "ICLR.cc/2025/Conference/Submission14236/Reviewer_rcVF",
      "actor": "Reviewer rcVF",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 5,
      "confidence": 4,
      "soundness": 4,
      "presentation": 2,
      "contribution": 3,
      "strengths": "1.\tThe correlation of Hypothesis 1 with the proposed method is well elaborated and explained.\n2.\tThe structure of the paper is clear and easy to follow.",
      "weaknesses": "1.\tLack of related work. Context-aware dynamic draft token tree is not a new idea. I would like to draw your attention to a very related work: “EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees” (EMNLP'24). This paper also proposes adopting dynamic draft token trees and claims a strong positive correlation between the draft model confidence score and the acceptance rate of the token. Another relevant paper is “Dynamic Depth Decoding: Faster Speculative Decoding for LLMs,” which further improves performance by dynamic depth. The methodology of EAGLE-2 is quite similar to this paper but differs in the tree construction method. Including this work in your paper and providing necessary discussion is essential.\n2.\tExperimental setup and results are weak. First, the dataset is too limited. I recommend adding more datasets like MT-Bench (Zheng et al., 2023), HumanEval (Chen et al., 2021), and GSM8K (Cobbe et al., 2021). Second, the 9.1× speedup is compared with the autoregressive method, and when compared with static tree methods like Sequoia, the results are much less overwhelming. Considering that the experimental setup lacks comparison with state-of-the-art dynamic draft token tree methods, the experiment does not fully convince me of the merits of this methodology.\n3.\tWriting needs improvement. Section 4.2 is hard to follow. The presentation of Figure 3 should be improved. Additionally, Figure 4 is not clear; please increase the font size.",
      "questions": "More convincing experimental results that compare with more relevant related work.",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "This work proposes a method to dynamically expand the token tree based on the draft distribution. A key difference between this work and existing approaches is that it introduces a smooth dynamic draft token tree construction method, which expands the tree along both width and depth without hyperparameter setup, within the given token budget. However, related works are missing, and the experimental setup should be properly improved."
    },
    {
      "note_id": "E6rHmk7S9P",
      "replyto": "orr5uPZY28",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-11-03 23:44:01.294000",
      "modified": "2024-11-12 16:14:32.446000",
      "signatures": "ICLR.cc/2025/Conference/Submission14236/Reviewer_SL3U",
      "actor": "Reviewer SL3U",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 6,
      "confidence": 2,
      "soundness": 3,
      "presentation": 2,
      "contribution": 2,
      "strengths": "1. Strong Theoretical Foundation\n- Provides rigorous theoretical analysis linking draft distribution to acceptance rate\n- Includes formal proofs of optimality under stated assumptions\n- Clearly bridges theoretical insights with practical implementation\n\n2. Novel Technical Contributions\n- Introduces an innovative dynamic token tree construction approach\n- Develops efficient algorithms for both fixed-size and threshold-based tree construction\n- Proposes block-sparsity friendly token ordering for optimization\n\n3. Comprehensive Empirical Evaluation\n- Tests across multiple model scales (7B to 70B parameters)\n- Evaluates on diverse datasets (C4, OpenWebText, CNN DailyMail)\n- Compares against strong baselines (Specinfer, Sequoia)\n- Examines performance under different temperature settings\n\n4. Implementation Efficiency\n- Addresses practical concerns about overhead\n- Provides C++ implementation to minimize token tree construction costs\n- Includes detailed analysis of computation complexity",
      "weaknesses": "1. Limited Discussion of Limitations\n- Could elaborate more on scenarios where the method might not perform optimally\n- More discussion of the trade-offs between fixed-size and threshold-based approaches would be valuable\n\n2. Implementation Details\n- Some implementation specifics about the C++ optimizations could be expanded\n- Could provide more guidance on threshold selection for different scenarios\n\n3. Experimental Validation\n- Could include more ablation studies to isolate the impact of different components\n- Additional experiments on more diverse model architectures would strengthen generalizability claims",
      "questions": "None",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "This paper introduces DySpec, a novel approach to speculative decoding that employs a dynamic token tree structure to improve inference speed for large language models. The authors present both theoretical and empirical evidence showing that higher draft probabilities correlate with higher acceptance rates. Based on this insight, they develop a greedy strategy for dynamically expanding the token tree at runtime. The method achieves impressive results, demonstrating up to 9.1× throughput improvement and 9.4× reduction in latency on Llama2-70B under low temperature settings, outperforming existing methods like Specinfer and Sequoia."
    },
    {
      "note_id": "VyE6cLOeF4",
      "replyto": "orr5uPZY28",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-10-31 15:55:12.776000",
      "modified": "2024-11-12 16:14:32.389000",
      "signatures": "ICLR.cc/2025/Conference/Submission14236/Reviewer_Dmmc",
      "actor": "Reviewer Dmmc",
      "readers": "everyone",
      "title": "The authors propose dyspec to generate an optimal tree. The core idea is based on the idea that the target distribution and draft distribution should match.\n\nThe authors based on the idea propose an a",
      "rating_or_recommendation": 5,
      "confidence": 4,
      "soundness": 3,
      "presentation": 2,
      "contribution": 3,
      "strengths": "- The proposed idea is quite useful and can provide significant speedups for tree based speculative decoding methods. \n\n- The overheads reported our negligible.",
      "weaknesses": "- See the summary section please.",
      "questions": "- See the summary section \n\nPlease answer some of the question there. I am happy to bump up the score to 6.",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "Summary:\n\nThe authors propose dyspec to generate an optimal tree. The core idea is based on the idea that the target distribution and draft distribution should match.\n\nThe authors based on the idea propose an algorithm to come up with optimal tree. They overcome several implementation challenges and achieve reasonable speedups compared to existing baselines.\n\n“DYSPEC achieves a 9.1× throughput improvement and 9.4× reduction in latency.” ([“DySpec”, p. 2]-> Should compare to SpecInfr or Medusa\n\n“Figure 2: Connection between acceptance rate/target distribution and draft distribution on CNN DailyMail.The density of each block is normalized by column.” ([“DySpec”, p. 3] -> Can you please explain this figure. I think it’s the main motivation for your method, however it is not clearly explained, what this figure is showing.\n\n“Specinfer-Baseline” ([“DySpec”, p. 7] -> Specifinfer requires training the models. What have authors done here.\n\n“DYSPEC leverages CUDA Graph to capture 129 different input lengths ranging from 128 to 258” ([“DySpec”, p. 7-> What is the significance of CUDA Graph here, my understanding is CUDA graph is a mechanism to launch multiple kernels at the same time on the GPU to minimize the overhead of kernel dispatch\n\n“We selected Llama2-7B as the draft model” ([“DySpec”, p. 7] -> What happens when you use the 68M model ?\n\n“Set the maximum draft token tree size to 64, DYSPEC achieves up to a 9.1x improvement in throughput and a 9.4x reduction in latency compared to auto-regressive generation” ([“DySpec”, p. 8]-> Unfair comparison, compare to baselines\n\nAdditional experiments -\n\nI would really like to experimentally understand the optimality of your tree. Will it be possible to construct an optimal tree based on some post-hoc data and compare it with the tree generated by Dyspec."
    },
    {
      "note_id": "YaF71CV6ww",
      "replyto": "orr5uPZY28",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-10-27 18:18:20.074000",
      "modified": "2024-11-12 16:14:32.341000",
      "signatures": "ICLR.cc/2025/Conference/Submission14236/Reviewer_Jh6N",
      "actor": "Reviewer Jh6N",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 3,
      "confidence": 5,
      "soundness": 2,
      "presentation": 2,
      "contribution": 2,
      "strengths": "The proposed token selection method demonstrates improvement over existing methods such as Sequoia and Specinfer.",
      "weaknesses": "1. The paper lacks discussion on existing works that share very similar ideas (see Questions 1 and 2). \n1. The experimental results do not sufficiently validate the method's effectiveness from various perspectives (see Questions 3 and 4).",
      "questions": "1. There are concurrent works using similar ideas. For instance, EAGLE 2 (https://arxiv.org/abs/2406.16858) attempts to maximize the acceptance rate based on a similar intuition (see Figure 6 in their paper). The authors should mention these works. What are the differences between your method and EAGLE 2?\n1. Dynamic tree-based selection methods have appeared in prior literature. For example, Recurrent Drafter (https://arxiv.org/abs/2403.09919) proposes an RNN draft model and uses beam search for adaptive token selection. Did you modify the draft model architecture in your approach?\n1. In practice, small draft models may be overconfident about incorrect answers in reasoning tasks. Have you studied your Hypothesis 1 across different tasks and analyzed the failure examples?\n1. Does your method support batch inference? Have you experimented with large batch sizes to push your algorithm to its computational limits and test its throughput?",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "This paper proposes a draft token selection method in speculative decoding aimed at improving the token acceptance rate. The core idea is to use the draft model's prediction score as evidence to infer the token acceptance rate and use this information to select more promising tokens. The authors provide both theoretical and empirical analyses to support their approach."
    }
  ]
}
