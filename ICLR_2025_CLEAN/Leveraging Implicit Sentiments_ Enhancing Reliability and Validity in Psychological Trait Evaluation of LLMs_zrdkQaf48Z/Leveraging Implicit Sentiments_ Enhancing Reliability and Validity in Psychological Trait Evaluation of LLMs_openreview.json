{
  "paper": {
    "id": "zrdkQaf48Z",
    "forum": "zrdkQaf48Z",
    "title": "Leveraging Implicit Sentiments: Enhancing Reliability and Validity in Psychological Trait Evaluation of LLMs",
    "authors": "Huanhuan Ma, Haisong Gong, Xiaoyuan Yi, Xing Xie, Dongkuan Xu",
    "keywords": "LLM, Benchmark, Evaluation, Psychometrics",
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to their increasing integration into human life. Understanding their inherent characteristics, such as personalities, temperaments, and emotions, is essential for responsible AI development. However, current psychometric evaluations of LLMs, often derived from human psychological assessments, encounter significant limitations in terms of reliability and validity. Test results reveal that models frequently refuse to provide anthropomorphic responses and exhibit inconsistent scores across various scenarios. Moreover, human-derived theories may not accurately predict model behavior in practical real-world applications.\nTo address these limitations, we propose Core Sentiment Inventory (CSI), a novel evaluation instrument inspired by the Implicit Association Test (IAT). CSI is built from the ground up with a significantly broader range of stimuli words than traditional assessments. CSI covers both English and Chinese to implicitly evaluate models’ sentiment tendencies, which allows for a much more comprehensive assessment.\nThrough extensive experiments, we demonstrate that CSI effectively quantifies models’ sentiments, revealing nuanced emotional patterns that vary significantly across languages and contexts. CSI significantly improves reliability, yielding more consistent results and a reduced reluctance rate, and enhances predictive power by effectively capturing models’ emotional tendencies. These findings validate CSI as a robust and insightful tool for evaluating the psychological traits of LLMs, offering a more reliable alternative to traditional methods.",
    "pdf_link": "https://openreview.net/pdf/404bca525ca6ce84d23a0c6a6cee27f56f8a84aa.pdf",
    "submission_date": "2024-09-28 11:26:30.123000"
  },
  "reviews": [
    {
      "note_id": "fj8DLfAbBy",
      "replyto": "zrdkQaf48Z",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-11-05 20:59:09.362000",
      "modified": "2024-11-12 16:07:50.924000",
      "signatures": "ICLR.cc/2025/Conference/Submission14193/Reviewer_jSVf",
      "actor": "Reviewer jSVf",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 3,
      "confidence": 3,
      "soundness": 2,
      "presentation": 4,
      "contribution": 2,
      "strengths": "Reasons to accept\n- The presentation of the method is clear and concise.\n- Measuring LLM’s sentiment tendencies is vital to identify biases and building fair systems.\n- The evaluation is performed both in English and Chinese with the approach being easily extended to other languages.",
      "weaknesses": "Reasons to reject\n\nWhile the paper has merit, I see the some critical flaws presented below:\n\n- The decision to pick all top nouns/verbs is questionable to me. Yes, nouns and verbs “tend” to be neutral. However, this is not always the case. From the examples in Table 2, some of these words are clearly polarized. “Improve” has positive connotations, as well as “team”. I believe there needs to be a manual filtering step where these words are removed to ensure reliable results. As it stands, I think the model does not have implicit biases if it assigns “improve” as positive.\n- Design choices are not well-motivated. The approach does multiple predictions for the same word and the method shuffles the order of words to measure inconsistency. (1) Given this goal, why is temperature T set to 0? Wouldn’t a higher temperature better indicate the model uncertainty in assigning tragedy/comedy? (2) Why is the number of words sampled equal to 30? What happens with n > 30 or n < 30. Why wasn’t the number of words picked so it maximizes the context window?\n- The prompt design is biased. (3) Why is neutral not a valid option? A very strong model with perfect instruction following capabilities will always pick one of the two (comedy/tragedy) and will never output “neutral”. (4) Given the definition of neutral score as N_{inconsistent} / N, I am wondering what percentage of words the model predicted in opposite categories? I think they should be very few. In this case, neutral score is solely determined by poor instruction following, not implicit biases.",
      "questions": "See numbered questions above: 1, 2, 3, 4",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "The paper introduces Core Sentiment Inventory (CSI), a multilingual evaluation benchmark aimed at assessing the sentiment tendencies of LLMs in an implicit manner. The approach leverages 5,000 neutral words from English and Chinese and prompts the LLM to express polarity towards these neutral words. By assessing this polarity, the paper measures the biases of the models with respect to optimism or pessimism. To quantify the reliability of CSI, the paper validates the method against BFI, where CSI shows significant decrease in reluctance (i.e., model punting)."
    },
    {
      "note_id": "Zo9D2nRoNf",
      "replyto": "zrdkQaf48Z",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-11-04 03:44:04.950000",
      "modified": "2024-11-12 16:07:50.957000",
      "signatures": "ICLR.cc/2025/Conference/Submission14193/Reviewer_4sSm",
      "actor": "Reviewer 4sSm",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 3,
      "confidence": 4,
      "soundness": 2,
      "presentation": 2,
      "contribution": 2,
      "strengths": "•  The CSI can effectively quantify the emotions of models, reflecting the emotional tendencies of LLMs.\n\n•  It effectively reduces the issues of reluctance and inconsistency in traditional psychological scales.\n\n•  The use of representative neutral words in constructing the CSI reduces the potential emotional orientation of the words themselves, better reflecting the internal emotional associations of LLMs.\n\n•  It explores the impact of different language environments on the emotional tendencies of LLMs.",
      "weaknesses": "•  The constructed CSI is only used to assess the emotions of LLMs and has not been extended to other psychometric fields, such as personality or moral decision-making.\n\n•  It does not introduce the calculation methods for consistency rate and reluctance rate.",
      "questions": "•  Discuss how CSI can improve existing psychological scales designed for humans.\n\n•  Further explore the unintentional biases that language models may have towards everyday concepts as mentioned in section 4.1.\n\n•  On line 424, it might be: “e.g., five positive words, four neutral words and one negative words, and so on.”",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "This paper introduces a novel assessment method known as the Core Sentiment Inventory (CSI) for evaluating the emotional tendencies of large language models (LLMs). Inspired by the Implicit Association Test (IAT), the CSI aims to provide a more reliable and effective way to assess the implicit emotional characteristics of LLMs. It addresses the limitations of traditional psychometric methods, such as model reluctance and inconsistency."
    },
    {
      "note_id": "exzZKhXQD3",
      "replyto": "zrdkQaf48Z",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-11-03 07:16:20.420000",
      "modified": "2024-11-27 08:22:01.163000",
      "signatures": "ICLR.cc/2025/Conference/Submission14193/Reviewer_w2P7",
      "actor": "Reviewer w2P7",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 6,
      "confidence": 3,
      "soundness": 3,
      "presentation": 3,
      "contribution": 2,
      "strengths": "The paper proposes an elegant approach based on the adaptation of existing psychometric tools (IAT).\n\nThe paper is well written and easy to follow.",
      "weaknesses": "Although an enjoyable read, the work falls short when it comes to the experimental setup.\n\nFirst, while I consider the proposed method more elegant and effective than human-tailored alternatives such as BFI, I am not convinced by the preliminary reliability tests conducted: it can be argued than reluctance is due to post-training strategies (e.g. guardrails, instruction-tuning), thus a different choice of (accessible) LLMs could have been more convincing -- e.g. the first Mistral release.\n\nSecond, some design choices seem discretional and not thoroughly justified: for instance, the choice of the words \"comedy\" / \"tragedy\" used as classes seems arbitrary.",
      "questions": "- did you consider using alternatives to \"comedy\" / \"tragedy\" (e.g. \"fun\", \"good\", \"dramatic\", \"bad\")?\n\n- did you consider LLMs with no significant guardrails (such as, if I remember correctly, the first Mistral)?\n\n- all models used in the paper are multilingual, have you considered prompting in cross-lingual setups (e.g. chinese prompt for english CSI) for additional reliability indications?",
      "ethics_flag": [
        "No ethics review needed."
      ],
      "code_of_conduct": "Yes",
      "body": "The authors propose Core Sentiment Inventory, a psychometric evaluation framework to assess LLMs' sentiment tendencies.\n\nThe experimental setup covers two languages, English and Chinese, 2 open-weight LLMs (LLama3.1-70B and Qwen2-72B), and 4 closed/proprietary LLMs (GPT-4o, two GPT4 checkpoints, and GPT-3.5).\n\nThe CSI consists of the 5k most frequent emotionally neutral words; it is assumed that noun and verbs are neutral, and thus the CSI word lists consist of the top-5k noun/verbs in the corpora.\n\nThe LLM is then provided with N words picked from the wordlist, and asked to to associate each word with \"comedy\" or \"tragedy\", thus revealing a sentiment bias for each word."
    },
    {
      "note_id": "yOHVEmfYWQ",
      "replyto": "zrdkQaf48Z",
      "invitation": "",
      "note_type": null,
      "decision_label": null,
      "created": "2024-10-29 03:03:21.773000",
      "modified": "2024-11-12 16:07:50.430000",
      "signatures": "ICLR.cc/2025/Conference/Submission14193/Reviewer_QMAg",
      "actor": "Reviewer QMAg",
      "readers": "everyone",
      "title": null,
      "rating_or_recommendation": 5,
      "confidence": 4,
      "soundness": 3,
      "presentation": 2,
      "contribution": 2,
      "strengths": "CSI represents an interesting attempt to create a psychometric assessment tool tailored for LLMs, addressing concerns around LLM reluctance and consistency with human-designed psychometric scales.\n\nThe bilingual approach (English and Chinese) is a notable effort to capture linguistic and cultural variance in model behaviors, which is increasingly important as LLMs are deployed globally.\n\nThe experiments cover several dimensions of reliability and validity, with additional sentiment analyses through story generation, providing a range of quantitative metrics.",
      "weaknesses": "The paper does not sufficiently justify the underlying premise that implicit sentiment tests designed for humans (like IAT) can meaningfully assess non-human entities like LLMs. The model’s association of specific words with positive or negative sentiments may not translate into meaningful or actionable insights about its “psychological traits,” as LLMs lack actual consciousness or subjective experience.\n\nCSI is evaluated solely through internal metrics without external validation from human experts in psychometrics or linguistics. Given the novelty of the tool, expert evaluation is essential to substantiate the claims of reliability and practical value, particularly for a method positioned as a \"psychological trait\" assessment.\n\nThe word set of 5,000 items lacks diversity and cultural depth, and it is unclear how these words were chosen or if they were screened for cultural or contextual biases. This oversight introduces potential biases that could skew CSI’s predictive power and undermine its reliability across varied contexts.\n\nMany new mental health-based LLMs are not cited to show the differences  anf effectiveness of this paper.",
      "questions": "See above",
      "ethics_flag": [
        "Yes, Privacy, security and safety"
      ],
      "code_of_conduct": "Yes",
      "body": "The paper introduces the Core Sentiment Inventory (CSI), a new evaluation method inspired by the Implicit Association Test (IAT) to assess the implicit sentiment tendencies of large language models (LLMs). The approach aims to provide a reliable and valid measure of LLMs' optimism, pessimism, and neutrality in both English and Chinese, surpassing conventional human-centric psychometric tests like the Big Five Inventory (BFI). The authors present experimental results that claim improved reliability, reduced reluctance rates, and strong predictive power for CSI."
    }
  ]
}
